{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os \n",
    "import random\n",
    "import tweepy\n",
    "from os.path import exists\n",
    "from time import strftime, localtime, sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#get authorization squared away first\n",
    "\n",
    "# authorization of API key and API secret\n",
    "auth = tweepy.OAuthHandler('Your API key here', \n",
    "                           'Your API secret here')\n",
    "  \n",
    "# set access to user's access key and access secret \n",
    "auth.set_access_token('Your access key here', \n",
    "                      'Your access secret here')\n",
    "\n",
    "# calling the api with our authentication\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function does all of the actual grunt work & tweeting\n",
    "\n",
    "def auto_tweet_manager(original_df_path, media_path,):\n",
    "    \n",
    "    remaining_nft_path = 'Remaining NFTs.p'\n",
    "    tweet_log_path = 'Tweet Log.p'\n",
    "    \n",
    "    #if no path is provided for the remaining NFT df, assing one and create the df, otherwise load it\n",
    "    if exists(remaining_nft_path):\n",
    "        remaining_nfts = pd.read_pickle(remaining_nft_path)\n",
    "    else:\n",
    "        remaining_nfts = pd.read_pickle(original_df_path)\n",
    "        \n",
    "    #if no tweetlog was provided, create one, otherwise load it\n",
    "    if exists(tweet_log_path):\n",
    "        tweet_log = pd.read_pickle(tweet_log_path)\n",
    "    else:\n",
    "        tweet_log = pd.DataFrame(columns=['Tweet_Time','Tweet_Data','name'])        \n",
    "        \n",
    "    \n",
    "    #list all of the NFT filenames available to tweet, from the remaining NFT dataframe\n",
    "    #randomly list all of the NFT filenames available to tweet from the remaining NFT dataframe\n",
    "    remaining_names = list(remaining_nfts['name'])\n",
    "    random.shuffle(remaining_names)\n",
    "\n",
    "    #choose one NFT name at random\n",
    "    current_nft = random.choice(remaining_names)\n",
    "    #double check this NFT is not already in the 'tweet_log'\n",
    "    tweets_logged_names = tweet_log['name'].tolist()\n",
    "    if current_nft in tweets_logged_names:\n",
    "        raise Exception('This NFT was already tweeted!')\n",
    "        \n",
    "    #pull the NFT's info from the dataframe\n",
    "    current_nft_data = remaining_nfts[remaining_nfts['name']==current_nft].values.tolist()[0]\n",
    "    #now we have a list of name, rectangles, circles, lines, spunk, kick, & BG color, and it's index\n",
    "    current_name = current_nft_data[0]\n",
    "    current_rect = current_nft_data[1]\n",
    "    current_circ = current_nft_data[2]\n",
    "    current_line = current_nft_data[3]\n",
    "    current_spunk = current_nft_data[4]\n",
    "    current_kick = current_nft_data[5]\n",
    "    current_bg = current_nft_data[6].capitalize()\n",
    "    current_index = remaining_nfts[remaining_nfts['name']==current_nft].index.tolist()[0]\n",
    "\n",
    "    #craft a tweet using this information\n",
    "\n",
    "    #use plural descriptors if needed\n",
    "    if current_rect == '1':\n",
    "        plural_rect = 'rectangle'\n",
    "    else:\n",
    "        plural_rect = 'rectangles'\n",
    "    if current_circ == '1':\n",
    "        plural_circ = 'circle'\n",
    "    else:\n",
    "        plural_circ = 'circles'\n",
    "    if current_line == '1':\n",
    "        plural_line = 'line'\n",
    "    else:\n",
    "        plural_line = 'lines'\n",
    "\n",
    "    #format our tweet using the NFT specific information\n",
    "    text = f'\"{current_name.split(\".\")[0]}\" contains {current_rect} {plural_rect}, {current_circ} \\\n",
    "{plural_circ}, {current_line} {plural_line}, and has a {current_bg} background. It boasts a \\\n",
    "spunk rating of {current_spunk} & a kick rating of {current_kick}. Modern Abstractions #{current_index}. \\\n",
    "#NFTs #nftart #ModernAbstractions'\n",
    "\n",
    "    #also determine the exact path to our media file\n",
    "    current_path = f'{media_path}/{current_nft}'\n",
    "    \n",
    "    #create & publish the tweet\n",
    "    tweet_data = api.update_status_with_media(text, current_path)\n",
    "\n",
    "    #get the NFT data as a pandas series from the 'remaining_nfts' dataframe\n",
    "    current_data = remaining_nfts[remaining_nfts['name']==current_nft]\n",
    "\n",
    "    #add the NFT data to our 'tweet_log' dataframe\n",
    "    tweet_log = tweet_log.append(current_data)\n",
    "\n",
    "    #also add the time & date it was tweeted, and the tweet data itself\n",
    "    tweet_log.at[current_index,'Tweet_Time'] = strftime(\"%B %-d, %Y @ %-I:%M %p %Z\", localtime())\n",
    "    tweet_log.at[current_index,'Tweet_Data'] = tweet_data\n",
    "\n",
    "    #remove any duplicate entries\n",
    "    tweet_log.drop_duplicates('name', inplace=True)\n",
    "\n",
    "    #now remove this NFT entry from the 'remaining_NFTs' dataframe\n",
    "    remaining_nfts.drop(current_index, inplace=True)\n",
    "    \n",
    "    #finally save hardcopy files for the 'tweet_log' & 'remaining_nft' dataframes\n",
    "    remaining_nfts.to_pickle(remaining_nft_path)\n",
    "    tweet_log.to_pickle(tweet_log_path)\n",
    "    \n",
    "    #also save them as CSV files\n",
    "    remaining_nfts_csv_path = remaining_nft_path.split('.')[0]+'.csv'\n",
    "    remaining_nfts.to_csv(remaining_nfts_csv_path)\n",
    "    tweet_log_csv_path = tweet_log_path.split('.')[0]+'.csv'\n",
    "    tweet_log.to_csv(tweet_log_csv_path)\n",
    "    \n",
    "    tweet_time = tweet_log.at[current_index,'Tweet_Time']\n",
    "    end_message = f'Successfully tweeted about {current_name.split(\".\")[0]} on {tweet_time}'\n",
    "    \n",
    "    return end_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now put the function to use, tweeting every ~15 minutes\n",
    "\n",
    "original_df_path = 'Full DataFrame.p'\n",
    "media_path = 'Images'\n",
    "\n",
    "while True:\n",
    "    auto_tweet_manager(original_df_path, media_path)\n",
    "    time.sleep(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
